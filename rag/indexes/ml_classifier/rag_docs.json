[
  {
    "text": "This project classifies German retail products into main categories, subcategories, tags, and diet labels based on product name and brand text. \nIt addresses the problem of organizing noisy retail catalog data into a consistent taxonomy for analytics or downstream filtering. \nThe ML task is multi-label text classification with a single mandatory main category and optional secondary labels. \nInput is a list of product names (optionally with brand); output is a table of predicted labels plus a main-category confidence score. \nThe system ships both an offline training pipeline and a Streamlit demo for interactive inference.",
    "project": "ML Classifier",
    "section_title": "1. Short Project Summary",
    "source": "README.md"
  },
  {
    "text": "The pipeline begins with raw product extracts from supermarket flyers and retailer sources stored as CSVs. \nA master product list is built by selecting `Produkt` and `Marke`, cleaning missing brands, deduplicating, and shuffling for batching. \nLabeling is performed via a semi-automated workflow where batches are sent to the OpenAI API to assign a single main category and optional sub/tag/diet labels. \nThese labeled batches are consolidated into `master_training.csv`, which becomes the supervised training set. \n\nText preprocessing is minimal and deterministic: the model concatenates `Produkt` and `Marke` into a single text field, lower-level cleaning happens during CSV preparation, and the classifier operates on the raw string. \nFeature extraction uses character n-gram TF-IDF (`analyzer=\"char_wb\"`, n-grams 3–5) to capture spelling variants, abbreviations, and short product tokens common in retail text. \nThe model is a One-vs-Rest Logistic Regression classifier, which supports multi-label outputs while remaining interpretable and fast to train on modest data. \nTraining writes both the fitted pipeline (`category_classifier.pkl`) and the label schema (`label_columns.pkl`) for consistent inference. \n\nTF-IDF is used instead of neural embeddings because the dataset is small-to-midsized, labels are sparse, and the pipeline needs transparency and low infrastructure overhead. \nThis assumes that surface-form character patterns are sufficient to separate categories, and that semantic generalization beyond observed strings is limited. \nAs a result, performance will degrade on unseen product naming conventions or languages without retraining or richer embeddings.",
    "project": "ML Classifier",
    "section_title": "2. Technical Overview",
    "source": "README.md"
  },
  {
    "text": "```\nML_category_classifier\n├── .idea\n│   ├── inspectionProfiles\n│   │   └── profiles_settings.xml\n│   ├── .gitignore\n│   ├── misc.xml\n│   ├── ML_category_classifier.iml\n│   ├── modules.xml\n│   └── vcs.xml\n├── app\n│   └── portfolio_app.py\n├── ML Models\n│   └── ml_category_classifier\n│       ├── artifacts\n│       │   ├── category_classifier.pkl\n│       │   ├── category_model.pkl\n│       │   ├── label_columns.pkl\n│       │   └── tfidf_vectorizer.pkl\n│       ├── data\n│       │   ├── master\n│       │   │   └── master_products.csv\n│       │   ├── raw extracts\n│       │   │   ├── aldi_preisaktion_2025-12-14_csv_ml_train.csv\n│       │   │   ├── aldi_sued_04.10-01.11__2025-10-13_csv_ml_train.csv\n│       │   │   ├── kaufland_angebote_dedup_2025-11-30_11-55_csv_ml_train.csv\n│       │   │   ├── netto_angebote_2025-12-14_csv_ml_train.csv\n│       │   │   ├── rewe_angebote_107produkte_2025-11-17_bis_2025-11-23_csv_ml_train.csv\n│       │   │   ├── rewe_angebote_108produkte_2025-11-10_bis_2025-11-16_csv_ml_train.csv\n│       │   │   ├── rewe_angebote_332produkte_2025-12-15_bis_2025-12-21_csv_ml_train.csv\n│       │   │   └── rossmann13-17.10__2025-10-13_csv_ml_train.csv\n│       │   ├── raw_flyers_processed\n│       │   │   ├── aldi_preisaktion_2025-12-14.csv\n│       │   │   ├── aldi_sued_04.10-01.11__2025-10-13.csv\n│       │   │   ├── kaufland_angebote_dedup_2025-11-30_11-55.csv\n│       │   │   ├── netto_angebote_2025-12-14.csv\n│       │   │   ├── rewe_angebote_107produkte_2025-11-17_bis_2025-11-23.csv\n│       │   │   ├── rewe_angebote_108produkte_2025-11-10_bis_2025-11-16.csv\n│       │   │   ├── rewe_angebote_332produkte_2025-12-15_bis_2025-12-21.csv\n│       │   │   └── rossmann13-17.10__2025-10-13.csv\n│       │   ├── training\n│       │   │   └── master_training.csv\n│       │   ├── training_archive\n│       │   │   ├── batch_001.csv\n│       │   │   ├── batch_002.csv\n│       │   │   ├── batch_003.csv\n│       │   │   ├── batch_004.csv\n│       │   │   ├── batch_005.csv\n│       │   │   ├── batch_006.csv\n│       │   │   ├── batch_007.csv\n│       │   │   └── batch_008.csv\n│       │   ├── draw_training_batch.py\n│       │   ├── labeled_products.csv\n│       │   ├── raw_products.csv\n│       │   └── raw_products_labeled.csv\n│       ├── evaluation\n│       │   └── metrics.ipynb\n│       ├── inference\n│       │   └── classify_csv.py\n│       ├── labeling\n│       │   ├── archived\n│       │   │   ├── batch_001.json\n│       │   │   ├── batch_002.json\n│       │   │   ├── batch_003.json\n│       │   │   ├── batch_004.json\n│       │   │   ├── batch_005.json\n│       │   │   ├── batch_006.json\n│       │   │   ├── batch_007.json\n│       │   │   └── batch_008.json\n│       │   ├── labeled_batches\n│       │   │   ├── batch_001.csv\n│       │   │   ├── batch_002.csv\n│       │   │   ├── batch_003.csv\n│       │   │   ├── batch_004.csv\n│       │   │   ├── batch_005.csv\n│       │   │   ├── batch_006.csv\n│       │   │   ├── batch_007.csv\n│       │   │   ├── batch_008.csv\n│       │   │   └── batch_009.csv\n│       │   ├── training_archive\n│       │   │   └── training_batch_20251219_144116.csv\n│       │   ├── gpt_label_products.py\n│       │   └── json_to_master_training_csv.py\n│       ├── scripts\n│       │   ├── build_master_csv.py\n│       │   ├── extract_relevant_columns.py\n│       │   └── run_until_master.py\n│       ├── training\n│       │   ├── new\n│       │   └── train_classifier.py\n│       └── README.md\n└── requirements.txt\n```\n\n**Folder responsibilities**\n- `app/`: Streamlit UI for interactive classification; loads the trained pipeline and label schema and applies the same text concatenation used in training. \n- `ML Models/ml_category_classifier/artifacts/`: Serialized model artifacts, including the fitted TF-IDF + classifier pipeline and label column order. \n- `ML Models/ml_category_classifier/data/`: Raw extracts, processed flyer CSVs, master product list, and training datasets (including historical batch archives). \n- `ML Models/ml_category_classifier/labeling/`: GPT-assisted labeling workflow, archived JSON responses, and labeled CSV batches. \n- `ML Models/ml_category_classifier/scripts/`: Data preparation utilities for building the master CSV and extracting relevant columns. \n- `ML Models/ml_category_classifier/training/`: Training scripts and working directories for model training iterations. \n- `ML Models/ml_category_classifier/inference/`: Batch inference script for labeling CSVs using saved artifacts. \n- `ML Models/ml_category_classifier/evaluation/`: Notebook used for metrics analysis. \n\n**Folder interaction flow**\nData flows from `data/raw extracts` → `scripts/` (master list) → `labeling/` (GPT labels) → `data/training/master_training.csv` → `training/train_classifier.py` → `artifacts/`. \nInference reads `artifacts/` and applies predictions to `data/raw_products.csv` or the Streamlit UI in `app/`. \n\n**Where key concerns live**\n- **ML logic**: `training/train_classifier.py`, `inference/classify_csv.py`, and the model artifacts in `artifacts/`. \n- **Data preprocessing**: `scripts/` and `data/` (cleaning, deduplication, and batching). \n- **Experimentation**: `evaluation/metrics.ipynb` and `training/` iteration folders. \n- **Configuration**: Mostly embedded in scripts (paths, label schema, model settings); no standalone config module is present.",
    "project": "ML Classifier",
    "section_title": "3. Folder Structure (Core Section)",
    "source": "README.md"
  },
  {
    "text": "A classical ML pipeline was chosen to keep training reproducible and lightweight while working with sparse, noisy product text. \nTF-IDF with character n-grams captures short tokens and spelling variants common in retail catalogs, making it robust without requiring large embedding models. \nA linear One-vs-Rest classifier provides straightforward multi-label predictions and simplifies debugging with explicit probability outputs. \n\nModularity is achieved by separating data preparation, labeling, training, and inference into dedicated folders and scripts. \nThis allows the labeling workflow to evolve independently from the model training code and keeps artifacts versionable. \nTo scale, the project could add stronger quality checks for labels, move to word/phrase embeddings or transformer models, and introduce a configurable training pipeline. \nAnother extension would be an automated evaluation report and dataset versioning to compare model runs over time.",
    "project": "ML Classifier",
    "section_title": "4. Engineering & Design Decisions",
    "source": "README.md"
  },
  {
    "text": "This repository demonstrates applied NLP for product taxonomy classification using a multi-label pipeline. \nIt includes data ingestion, dataset curation, GPT-assisted labeling, and classic ML training with reproducible artifacts. \nThe structure highlights clear separation between preprocessing, modeling, and serving, which is relevant to ML engineering roles and applied data work. \nIt is most relevant for roles that value end-to-end ML pipelines, practical NLP classification, and lightweight model deployment.",
    "project": "ML Classifier",
    "section_title": "5. What This Project Demonstrates",
    "source": "README.md"
  },
  {
    "text": "ml_category_classifier\n└── README.md",
    "project": "ML Classifier",
    "section_title": "Folder Structure",
    "source": "folder_tree"
  }
]